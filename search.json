["Article One Machine Deep Learning in a Nutshell Modern machine learning method help to make decision and prediction from data. These covered areas from physical, management to financial science and applications. Similar to CAD, Computer Aided Design, human is making use of computer for CADM, Computer Aided Decision Making. The development of modern machine learning methods is important to human endeavor by advancing human’s knowledge to broader and deeper extends. Similar methods can be applied to engineering problem, product pricing problem or stock trading strategy decision making problem. Here we will go through the basics and some advance topics in following sequences: 1) Predict from component factors (linear regression) as a simple ranking method. 2) Make classification decisions by extending linear regression to logistical regression. 3) Patterns classification and decision makings. 4) Common pitfalls. From social or physical phenomenon, digitized information to data analysis. For session with the ‘challenge’ icon below, you can skip it without loss of reading continually but it will help you to understand the topic deeper for future’s real-life applications. ","Predict from component factors, linear regression Human predicts, from knowledge of known factors to unknown future and make decision. We will look at sky and decide whether we should bring an umbrella. If the sky is dark and cloudy, most people will bring an umbrella. A bank base on a person’s income, job nature, age and other component factors to make a decision of approving a credit card for him or not. In simplest mathematical term, it can be described by a simple equation as following. z = w 0 + w 1 x 1 + w 2 x 2 + w 3 x 3 Equ 1.0 For example, x 1 is income, x 2 is job nature and x 3 is age. We treat each factor as a predictor for the outcome z. For each factor, we weight it with some weights w 1 ,w 2 ,w 3 . Furthermore, when all the weighted stuffs add together, it must be greater than a threshold value for approving a credit card. Therefore if we select w 0 as a big enough negative number (say -100), then all the weighted sum w 1 x 1 + w 2 x 2 + w 3 x 3 must greater than 100 to make the outcome z positive. If z is positive, the bank will approve the credit card. Equ 1.0 is called linear regression [3]. The challenge here is how to select the weights ( w i ) such that above simple equation can be used for the bank’s manager as a guiding rule for approving the credit card. Similarly, if we can same approach to determine insurance premium decision, but the weights to achieve this will be difference for the credit card approval process. For more detail treatment on the credit card example, please refer to [1, 2] . Sometimes we can find the weights by analytical matrix algebra methods, but I will show only numerical methods here, as it can be used for a broader spectrum of problems by modern computer software easily. Most, if not all, of the machine deep learning methods use this as the basic unit to build highly complicated system from online store recommendation system to Google’s Alpha Go and Alpha Zero which outperform human in several Go competitions. Today, similar methods are using from financial trading system, genes classification to Covid-19 virus classification system. Human’s capabilities in understand the universe is extending to another limit that never happened in our history before. The system describe by Equ 1.0 can be build easy by Tensorflow Keras as following: Dense(units=1, name=z) Google Tensorflow called it Dense layer and it is one unit in a layer. Pictorial, it can be represented by a circle with weights around it. ","Figure 1.1 If we have 10 units in parallel, it can be described as following: Dense(10, name=Layer with 10 units”) By making use of this Dense layer, very complicate deep learning network can be built easily. If you prefer PyTorch’s syntax, you can refer to [4] which is called torch.nn.Linear() instead. The layers can be further cascaded in serial to form a deeper network. Tutorial 1.1 – Colab Exercise for Dense() To be continued …. Article Two: 1.1 Deep Machine Learning’s Mechanics in details 1.1.1 Perceptron The basic unit of deep neural networks is a perceptron. This unit can be cascaded in parallel as a layer; the layers can be cascaded in serial to form a deep network. The parallel cascaded units dichotomize (divides into two groups) input space differently if the weights w i are different after training [1,2]. The serially cascaded layers will pick-up the previous layer's outputs and repeat the dichotomy division process repeatedly. When the breadth of parallel cascade and depth of serial cascade are big enough to match the dataset's complexity (input space), it can classify and represent complicated problems effectively. In theory, when the number of dichotomy division processes is large enough, it can distinguish every element of data in the input space (dataset); however, in practice, we have to balance computational cost, generalization capability, and noise rejection in reducing model complexity and avoid overfitting problem. Originally, the neuron was proposed to be an abstract representation of the real neuron in the brain. When this specific neuron is polarized enough, it send an action potential spike via its axon to the other ","adjacent neurons. In an actual biological system, these steps do not occur at once but at a more granular scale. Spiking neural networks are better suited in describing the underlying biological processes. But at the current state of art, the deep learning community relies more on deep artificial neural networks (ANNs). Numerical inputs and outputs formalize the neurons in the neural network by a system of linear equations (regression equation). Equation 1.1. is an example of regression equation as a starting mathematical description for a complicated deep network. z = w 0 + w 1 x 1 + w 2 x 2 + w 3 x 3 Equation 1.1 where w 0 is the bias b Furthermore, at the current state of the art, the deep learning communities always normalize input dataset data to be within [-1, 1] and initialize w i close to zero, which makes the regression similar to cosine similarly [27] measurement and these treatments and the logistic regression method fit well to pattern recognition tasks for a lot of decision-making process. Figure. 1.1 shows a typical artificial neuron defined by Equation. 1.1 and together with some nonlinear output function (e.g., ReLu, which is max(z,0) ) can execute simple classificational decision-making, which can date back to ancient Chinese philosophers' I-Ching (Yijifng) [43] dichotomy method. This base unit becomes a dichotomous classifier that divides input space into two groups. When it is cascaded in parallel and then in serial, a complicated deep learning network is formed, as shown in Figure 1.2. Figure 1.1 ","It can be a many-to-many relationship as shown in Figure 1.2, and a neuron in one layer aggregates the signals being passed through from its input neurons from the previous layer. Following is a formal description of the connecting weights and activation functions structure by the language of linear algebra in a more compact and precise format. Figure 1.2 A deep network becomes a hierarchical composite model where each layer (figure 1.2) applies a linear transformation followed by a nonlinear function [24] to the preceding layer. Let X ∈ R NxD be the input data, where each row of X is a D-dimensional data point, and N is the number of training sample in the image space and W i ∈ R d i − 1 xd i be a matrix representing a linear transformation applied to the output of a layer i-1, X i − 1 ∈ R N xd i − 1 , to obtain a d i dimensional representation X i − 1 W i ∈ R Nxd i at layer i. For example, each column of W i could represent a convolution with some filter in convolutional neural networks or the application of a linear classifier in fully connected networks. Let ψ i : R→R be a nonlinear activation function, e.g., a sigmoid ψ i ( x ) = 1 /( 1 + e − x ) or a rectified linear unit ψ i ( x ) = max { 0 ,x } . This nonlinearity is applied to each entry of X i − 1 W i to generate the i-th layer of a neural network as X i = ψ i ( X i − 1 W ¿¿ i ) ¿ . The output X I of the network is thus given by: K ( X,W 1 ……W I ) = ψ I ¿¿ ) ― Equation 1.2 When the output dimensions of the network are C that equal to d I , K will be an N x C matrix, and C is the number of classes for a pattern recognition problem. Notice also that the mapping can be seen as a function of ","all the network weights W ={ W i } i = 1 I with a fixed input X and where the I layer is the last layer, output layer, with the indexed number I. We u8p8p;can view the composite mapping K as a function of the input data X with weights W , K ( X,W ) . Furthermore, we can say that the weights W in K ( X,W ) of a network trained by the input X characterized the network. This characterized network K is defined and says learned some conceptual knowledge from the input dataset X . It can easily be built as a class object by modern object-oriented programming language and a defined training method. We can form and vary a deep-learning network by varying I (number of layers), d i (width of the layer i) and ψ i (activation function in layer i) to form different types of architectures. When we use different kinds of ψ i for different layers, we can take them into account and see all the activation functions as ψ ={ ψ i } i = 1 I . Then K ( X,W,ψ ) is an extended description to cover varying activation functions. 1.1.2 Gradient Descent Algorithm and Error Back-Propagation These methods are optimization methods and key in searching optimum model parameters for a deep network to achieve neural networks' classification function. Gradient descent is an interactive method in which the objective is to minimize a cost function. It should be possible to compute the partial derivative of the function, which is slope or gradient. The weights are computed at each iteration by taking the negative of the derivative and by reducing the weights at each step by a learning rate (step size) multiplied by derivative so that the local minima can be achieved after enough iterations. So eventually, the iterations are stopped when it converges to minima, after which there is no further reduction in the cost function. There are different types of gradient descent, such as stochastic-gradient-descent and batch-gradient-descent. This algorithm provides a simple and efficient way to compute the gradient in a neural network and use it in conjunction with batch stochastic gradient descent, which is effective in practice and use in TensorFlow and PyTorch. Back propagation algorithm is used from layer to layer with the same descent method for deep learning neural network which has specific applications in many industry and commercial segments. ","Given a neural network and a loss function, the training of the neural network is formalized to learning its parameters W so that the loss L is minimized. Finding the minimum by searching W s.t. ∇ w L = 0 in a brute-force fashion is infeasible in practice, especially when the formula is as complex as a deep neural network. Therefore, we consider a process to approach the minima by small steps. The learning process of gradient descent starts from a randomly picked point, and the loss L decreases along with the update of parameters , each step based on the partial derivative ∂L ∂w . More specifically, the parameters are updated iteratively by w := w − α ∂L ∂w , where α is the learning rate of each step and W is the weights which include the biases b of each layer. This mechanism effectively reduces the weights if its output is over the supervised ground-truth value and increases the weights if the output is under the necessary ground truth. Back-Propagation (Rumelhart et al. 1986; LeCun et al. 2015) is a technique to compute the partial derivative ∂L ∂w in the network. To make the computation of ∂L ∂w clearer, an intermediate value δ = ∂L ∂w , which is the partial derivative of the loss L with respect to the layer's output z. Then, the partial derivatives of the loss L with respect to each parameter assemble ∂L ∂w , are computed based on the intermediate value δ. The layers are indexed as l= 1, 2, . . .L, where L is the index of the output layer, each layer has an output z l , an intermediate value ∂ i = ∂L ∂z l , and an activation output a l = f ( z l ) (where f is the activation function). For example if sigmoid is used as the activation function, following formulize the method. z l = W l a l − 1 where w 0 l is b l which is bias a l = f ( z l ) = 1 1 + e − z l L = 1 2 ‖y − a L ‖ 2 , By applying the gradient descent method to minimize the loss function, it can be shown that the weight update of each layer is governed by the following equation, which can be programmed iteratively. w l = w l − ∝ ∂L ∂w l ","1.2 Logistic Regression Logistic regression is used to deal with classification problems. It is different from basic linear regression by dot product; the monotonic transform [3] makes the output to a probability in [0,1]. Some examples of the practical application of Logistic regression are predicting the risk of developing a given disease, cancer diagnosis, predicting mortality of injured patients, and in engineering for predicting the probability of failure of a given process, system, or product. Logistic regression takes a monotonic transform of a simple linear regression as following. log ( p ( X ) 1 − p ( X ) ) = β 0 + β 1 X where p ( X ) is a probability of event X happen in a two classes classification problem. Instead of minimizing error, logistic regression maximize the likelihood of the probabilities where the transform function is e β 0 + β 1 X 1 + e β 0 + β 1 X which always outputs a number between [0,1] as a probability. When it is generalized to multiple variables [3], it is the Softmax function to handle multi-classes (C) classification problems. softmax( i ) = e Z i ∑ j = 1 C e Z j for i = 1, 2, …, C where Z i are the regressed outputs from its inputs, and softmax( i ) are the transformed outputs as the probabilities. ","1.3 Deep Convolution Neural Network In the big-data age with GPU, TPU, and other parallel computing devices, convolutional neural networks (CNNs) with more hidden layers have more complex network structure and more powerful feature learning and feature expression abilities than traditional machine learning methods. The convolution neural network model trained by the deep learning gradient descent algorithms has made remarkable achievements in many large-scale identification tasks in the field of computer vision since its introduction. Computer vision is a study of how to use computers in simulating human visual capability; its main task is through the collection of images (or video) analysis and understanding to make judgments or decisions. In the past few decades, Computer vision has made great progress and development. In image-based intelligent data, acquisition and processing have a significant role and impact. Image recognition technology can effectively deal with the detection and identification of specific target objects, image classification and subjective image quality assessment, and other issues. At present, image recognition technology has a great commercial market and good application prospects in Internet applications such as image search, commodity recommendation, user behavior analysis, and face recognition. Simultaneously, high-tech such as intelligent robots, unmanned driving, and unmanned aerial vehicle Industry and biology, medicine and geology, and many other disciplines have broad application prospects. In the early image recognition system, feature extraction methods such as scale-invariant feature transform and histogram of oriented gradients were used, and then the extracted feature input classifier for classification and recognition. These features are essentially a feature of manual design, for different identification problems, the extracted features directly impact the performance of the system, so the researchers need to study the problem areas to be studied to design adaptability for better features repeatedly, thereby improving system performance. The corresponding image recognition system is generally for a specific identification task, and the size of the data is not large, generalization ability is poor, it is difficult in the practical application of the problem to achieve accurate identification effect. Figure. 1.3. In 2006, Geoffery Hinton and his student, Ruslan Salakhutdinov, published an article [25] for dimensional reduction by the neural network. Two years later, the deep learning model based on convolution neural networks has achieved great performance improvement in large-scale image classification tasks and set off the upsurge of deep learning. At present, Google, Microsoft and Facebook, and many other companies competed to invest many resources, research, and development layout of the largescale depth of learning system. Humans recognize objects in an image with little effort, but for computer-aided systems, object recognition is a challenge for many decades. The premise of object detection lies in human visual attention, v isual attention of humans has been studied in many domains such as psychology and the human neural system. Researchers are ","working on imitating neural systems so that computers can visualize objects as humans do. Computer vision applications' task is to detect concentrated parts for classification, recognition or detection in images. State-of-the-art performance has been observed using specific machine learning techniques; among them, Convolution Neural Network (CNN) models are at the top in object detection and outperform humans in some cases. Ensemble methods [34, 35,37] train multiple learners to solve the same problem. In contrast to common learning approaches, which try to construct one learner from training data, ensemble methods try to build one or more learners and combine them. Ensemble learning is also called committee-based learning or learning multiple classifier systems. It is known that an ensemble [13] is usually more accurate than a single learner. The basic idea of deploying multiple voting models has been used in human society for a long time, such as committee members voting or board-of-directors voting in corporate organizations. ","2 References [1] S.I. Gallant, Perceptron-Based Learning Algorithms, IEEE Transactions on Neural Networks, June 1990 [2] Jurgen Schmidhuber, Deep learning in neural networks: An overview, Neural Networks Volume 61, January 2015, Pages 85-117 [3] T. Hastie R. Tibshirani J. Friedman, The Elements of Statistical Learning, 2017 4] T. Shimobaba, T. Kakue, and T. Ito. Convolutional neural network-based regression for depth prediction in digital holography. arXiv preprint arXiv:1802.00664 , 2018. [5] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems , pages 1097–1105, 2012. ","Reference: [1] Y.S. Abu-Mostafa, M. M. Ismail,  H.T. Lin, Learning From Data, a short course. [2] T.Hastie, R. Tibshirani, J. Friedman, The Elements of Statistical Learning: Data Mining, Inference, and Prediction, Second Edition. [3] https://en.wikipedia.org/wiki/Linear_regression#:~:text=In%20statistics%2C%20linear%20regression%20is,as%20dependent%20and%20independent%20variables [4] https://pytorch.org/tutorials/beginner/examples_nn/two_layer_net_nn.html Coding Exercise : Dense() : from tensorflow.keras.models import Sequential from tensorflow.keras.layers import Dense, Flatten, Softmax mode=Sequential() mode.add([Dense(64), input_shape=(64,64)]) "]