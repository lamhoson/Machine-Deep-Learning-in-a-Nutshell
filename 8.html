<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="X-UA-Compatible" content="IE=Edge" />
<meta charset="utf-8" />
</head>

<body style="margin: 0;">

<div id="p8" style="overflow: hidden; position: relative; background-color: white; width: 935px; height: 1210px;">

<!-- Begin shared CSS values -->
<style class="shared-css" type="text/css" >
.t {
	transform-origin: bottom left;
	z-index: 2;
	position: absolute;
	white-space: pre;
	overflow: visible;
	line-height: 1.5;
}
</style>
<!-- End shared CSS values -->


<!-- Begin inline CSS -->
<style type="text/css" >

#t1_8{left:110px;bottom:1086px;letter-spacing:0.1px;word-spacing:0.03px;}
#t2_8{left:55px;bottom:1063px;letter-spacing:0.06px;word-spacing:0.06px;}
#t3_8{left:166px;bottom:1064px;}
#t4_8{left:188px;bottom:1063px;letter-spacing:0.12px;word-spacing:0.02px;}
#t5_8{left:679px;bottom:1064px;}
#t6_8{left:700px;bottom:1063px;letter-spacing:-0.04px;}
#t7_8{left:727px;bottom:1066px;}
#t8_8{left:740px;bottom:1064px;}
#t9_8{left:752px;bottom:1066px;}
#ta_8{left:766px;bottom:1063px;letter-spacing:0.1px;word-spacing:0.04px;}
#tb_8{left:55px;bottom:1041px;letter-spacing:0.09px;word-spacing:0.06px;}
#tc_8{left:55px;bottom:1018px;letter-spacing:0.09px;word-spacing:0.06px;}
#td_8{left:55px;bottom:996px;letter-spacing:0.09px;word-spacing:0.05px;}
#te_8{left:55px;bottom:963px;letter-spacing:0.11px;word-spacing:0.01px;}
#tf_8{left:364px;bottom:975px;letter-spacing:2.57px;}
#tg_8{left:363px;bottom:952px;letter-spacing:2.63px;}
#th_8{left:394px;bottom:963px;letter-spacing:0.05px;word-spacing:0.06px;}
#ti_8{left:114px;bottom:898px;}
#tj_8{left:132px;bottom:898px;letter-spacing:0.09px;}
#tk_8{left:150px;bottom:899px;}
#tl_8{left:164px;bottom:899px;}
#tm_8{left:179px;bottom:899px;}
#tn_8{left:195px;bottom:910px;letter-spacing:3.79px;}
#to_8{left:193px;bottom:887px;letter-spacing:2.77px;}
#tp_8{left:220px;bottom:898px;letter-spacing:0.06px;word-spacing:0.05px;}
#tq_8{left:280px;bottom:898px;}
#tr_8{left:296px;bottom:898px;letter-spacing:0.08px;word-spacing:0.09px;}
#ts_8{left:566px;bottom:898px;}
#tt_8{left:587px;bottom:898px;letter-spacing:0.13px;word-spacing:-0.02px;}
#tu_8{left:55px;bottom:865px;letter-spacing:-0.09px;word-spacing:0.28px;}
#tv_8{left:55px;bottom:820px;letter-spacing:0.11px;word-spacing:0.04px;}
#tw_8{left:55px;bottom:798px;letter-spacing:0.12px;}
#tx_8{left:110px;bottom:740px;letter-spacing:0.1px;word-spacing:0.06px;}
#ty_8{left:55px;bottom:707px;letter-spacing:0.06px;}
#tz_8{left:136px;bottom:719px;letter-spacing:2.57px;}
#t10_8{left:135px;bottom:696px;letter-spacing:2.63px;}
#t11_8{left:169px;bottom:707px;letter-spacing:0.06px;word-spacing:0.06px;}
#t12_8{left:504px;bottom:719px;letter-spacing:2.57px;}
#t13_8{left:503px;bottom:696px;letter-spacing:2.63px;}
#t14_8{left:533px;bottom:707px;letter-spacing:0.01px;word-spacing:0.18px;}
#t15_8{left:759px;bottom:709px;}
#t16_8{left:769px;bottom:709px;}
#t17_8{left:787px;bottom:719px;letter-spacing:3.71px;}
#t18_8{left:786px;bottom:696px;letter-spacing:2.63px;}
#t19_8{left:813px;bottom:707px;letter-spacing:0.12px;word-spacing:-0.02px;}
#t1a_8{left:55px;bottom:674px;letter-spacing:0.11px;word-spacing:0.02px;}
#t1b_8{left:55px;bottom:641px;letter-spacing:0.1px;word-spacing:0.06px;}
#t1c_8{left:387px;bottom:653px;letter-spacing:2.75px;}
#t1d_8{left:385px;bottom:631px;letter-spacing:2.59px;}
#t1e_8{left:420px;bottom:641px;letter-spacing:0.1px;word-spacing:0.04px;}
#t1f_8{left:110px;bottom:608px;letter-spacing:0.07px;word-spacing:0.06px;}
#t1g_8{left:56px;bottom:573px;}
#t1h_8{left:64px;bottom:585px;}
#t1i_8{left:68px;bottom:574px;letter-spacing:0.08px;word-spacing:0.03px;}
#t1j_8{left:243px;bottom:577px;}
#t1k_8{left:252px;bottom:590px;}
#t1l_8{left:257px;bottom:577px;}
#t1m_8{left:274px;bottom:588px;letter-spacing:2.75px;}
#t1n_8{left:273px;bottom:561px;letter-spacing:3.77px;}
#t1o_8{left:293px;bottom:574px;}
#t1p_8{left:303px;bottom:574px;letter-spacing:0.12px;word-spacing:0.03px;}
#t1q_8{left:498px;bottom:573px;}
#t1r_8{left:508px;bottom:585px;}
#t1s_8{left:512px;bottom:573px;}
#t1t_8{left:527px;bottom:573px;}
#t1u_8{left:537px;bottom:573px;}
#t1v_8{left:543px;bottom:573px;}
#t1w_8{left:551px;bottom:585px;}
#t1x_8{left:556px;bottom:573px;}
#t1y_8{left:564px;bottom:574px;letter-spacing:0.1px;word-spacing:0.04px;}
#t1z_8{left:55px;bottom:540px;letter-spacing:0.1px;word-spacing:0.03px;}
#t20_8{left:111px;bottom:492px;}
#t21_8{left:119px;bottom:505px;}
#t22_8{left:123px;bottom:492px;}
#t23_8{left:138px;bottom:492px;}
#t24_8{left:155px;bottom:505px;}
#t25_8{left:160px;bottom:492px;}
#t26_8{left:171px;bottom:505px;}
#t27_8{left:174px;bottom:505px;}
#t28_8{left:182px;bottom:505px;}
#t29_8{left:193px;bottom:494px;letter-spacing:0.09px;}
#t2a_8{left:244px;bottom:494px;}
#t2b_8{left:257px;bottom:494px;}
#t2c_8{left:257px;bottom:506px;}
#t2d_8{left:264px;bottom:494px;letter-spacing:0.05px;word-spacing:-1.92px;}
#t2e_8{left:288px;bottom:506px;}
#t2f_8{left:297px;bottom:494px;letter-spacing:0.13px;word-spacing:-0.02px;}
#t2g_8{left:110px;bottom:461px;}
#t2h_8{left:120px;bottom:474px;}
#t2i_8{left:124px;bottom:461px;}
#t2j_8{left:139px;bottom:461px;}
#t2k_8{left:149px;bottom:460px;}
#t2l_8{left:155px;bottom:461px;}
#t2m_8{left:163px;bottom:474px;}
#t2n_8{left:167px;bottom:460px;}
#t2o_8{left:172px;bottom:461px;}
#t2p_8{left:207px;bottom:472px;}
#t2q_8{left:188px;bottom:444px;}
#t2r_8{left:198px;bottom:444px;}
#t2s_8{left:210px;bottom:444px;}
#t2t_8{left:218px;bottom:457px;}
#t2u_8{left:228px;bottom:457px;}
#t2v_8{left:233px;bottom:464px;}
#t2w_8{left:111px;bottom:414px;}
#t2x_8{left:121px;bottom:414px;}
#t2y_8{left:139px;bottom:424px;}
#t2z_8{left:139px;bottom:401px;}
#t30_8{left:151px;bottom:414px;letter-spacing:4.2px;}
#t31_8{left:171px;bottom:414px;}
#t32_8{left:186px;bottom:414px;}
#t33_8{left:196px;bottom:426px;}
#t34_8{left:204px;bottom:414px;}
#t35_8{left:209px;bottom:426px;}
#t36_8{left:215px;bottom:412px;}
#t37_8{left:110px;bottom:334px;letter-spacing:0.11px;word-spacing:0.05px;}
#t38_8{left:55px;bottom:312px;letter-spacing:0.07px;word-spacing:0.12px;}
#t39_8{left:55px;bottom:259px;}
#t3a_8{left:69px;bottom:271px;}
#t3b_8{left:72px;bottom:259px;}
#t3c_8{left:87px;bottom:259px;}
#t3d_8{left:101px;bottom:271px;}
#t3e_8{left:104px;bottom:259px;}
#t3f_8{left:119px;bottom:259px;}
#t3g_8{left:139px;bottom:269px;letter-spacing:2.57px;}
#t3h_8{left:135px;bottom:243px;letter-spacing:2.63px;}
#t3i_8{left:161px;bottom:255px;}

.s1_8{font-size:18px;font-family:Carlito_2d;color:#000;}
.s2_8{font-size:18px;font-family:LiberationSerif-Italic_1k;color:#000;}
.s3_8{font-size:18px;font-family:DejaVuSerif-Italic_1u;color:#000;}
.s4_8{font-size:11px;font-family:LiberationSerif-Italic_1k;color:#000;}
.s5_8{font-size:18px;font-family:OpenSymbol_2i;color:#000;}
.s6_8{font-size:21px;font-family:OpenSymbol_2i;color:#000;}
.s7_8{font-size:11px;font-family:OpenSymbol_2i;color:#000;}
.s8_8{font-size:11px;font-family:LiberationSerif_1p;color:#000;}
.s9_8{font-size:18px;font-family:LiberationSerif_1p;color:#000;}
.sa_8{font-size:7px;font-family:LiberationSerif-Italic_1k;color:#000;}
.t.v0_8{transform:scaleX(1.007);}
.t.v1_8{transform:scaleX(1.011);}
.t.v2_8{transform:scaleX(0.477);}
.t.v3_8{transform:scaleX(1.006);}
.t.v4_8{transform:scaleX(1.005);}
.t.v5_8{transform:scaleX(0.479);}
</style>
<!-- End inline CSS -->

<!-- Begin embedded font definitions -->
<style id="fonts8" type="text/css" >

@font-face {
	font-family: Carlito_2d;
	src: url("fonts/Carlito_2d.woff") format("woff");
}

@font-face {
	font-family: DejaVuSerif-Italic_1u;
	src: url("fonts/DejaVuSerif-Italic_1u.woff") format("woff");
}

@font-face {
	font-family: LiberationSerif-Italic_1k;
	src: url("fonts/LiberationSerif-Italic_1k.woff") format("woff");
}

@font-face {
	font-family: LiberationSerif_1p;
	src: url("fonts/LiberationSerif_1p.woff") format("woff");
}

@font-face {
	font-family: OpenSymbol_2i;
	src: url("fonts/OpenSymbol_2i.woff") format("woff");
}

</style>
<!-- End embedded font definitions -->

<!-- Begin page background -->
<div id="pg8Overlay" style="width:100%; height:100%; position:absolute; z-index:1; background-color:rgba(0,0,0,0); -webkit-user-select: none;"></div>
<div id="pg8" style="-webkit-user-select: none;"><object width="935" height="1210" data="8/8.svg" type="image/svg+xml" id="pdf8" style="width:935px; height:1210px; -moz-transform:scale(1); z-index: 0;"></object></div>
<!-- End page background -->


<!-- Begin text definitions (Positioned/styled in CSS) -->
<div id="t1_8" class="t s1_8">Given a neural network and a loss funcon, the training of the neural network is formalized to learning </div>
<div id="t2_8" class="t s1_8">its parameters </div>
<div id="t3_8" class="t v0_8 s2_8">W</div>
<div id="t4_8" class="t s1_8">so that the loss L is minimized. Finding the minimum by searching </div>
<div id="t5_8" class="t v0_8 s2_8">W</div>
<div id="t6_8" class="t s1_8">s.t. </div>
<div id="t7_8" class="t v1_8 s3_8">∇</div>
<div id="t8_8" class="t v1_8 s4_8">w</div>
<div id="t9_8" class="t v1_8 s2_8">L</div>
<div id="ta_8" class="t s1_8">= 0 in a brute-</div>
<div id="tb_8" class="t s1_8">force fashion is infeasible in pracce, especially when the formula is as complex as a deep neural network. </div>
<div id="tc_8" class="t s1_8">Therefore, we consider a process to approach the minima by small steps. The learning process of gradient </div>
<div id="td_8" class="t s1_8">descent starts from a randomly picked point, and the loss L decreases along with the update of parameters , </div>
<div id="te_8" class="t s1_8">each step based on the paral derivave </div>
<div id="tf_8" class="t s2_8">∂L</div>
<div id="tg_8" class="t s2_8">∂w</div>
<div id="th_8" class="t s1_8">. More speciﬁcally, the parameters are updated iteravely by</div>
<div id="ti_8" class="t v0_8 s2_8">w</div>
<div id="tj_8" class="t s1_8">:= </div>
<div id="tk_8" class="t s2_8">w</div>
<div id="tl_8" class="t s5_8">−</div>
<div id="tm_8" class="t s2_8">α</div>
<div id="tn_8" class="t s2_8">∂L</div>
<div id="to_8" class="t s2_8">∂w</div>
<div id="tp_8" class="t s1_8">, where </div>
<div id="tq_8" class="t v0_8 s2_8">α</div>
<div id="tr_8" class="t s1_8">is the learning rate of each step and </div>
<div id="ts_8" class="t v0_8 s2_8">W</div>
<div id="tt_8" class="t s1_8">is the weights which include the biases </div>
<div id="tu_8" class="t s1_8">b of each layer.</div>
<div id="tv_8" class="t s1_8">This mechanism eﬀecvely reduces the weights if its output is over the supervised ground-truth value and </div>
<div id="tw_8" class="t s1_8">increases the weights if the output is under the necessary ground truth.</div>
<div id="tx_8" class="t s1_8">Back-Propagaon (Rumelhart et al. 1986; LeCun et al. 2015) is a technique to compute the paral </div>
<div id="ty_8" class="t s1_8">derivave </div>
<div id="tz_8" class="t s2_8">∂L</div>
<div id="t10_8" class="t s2_8">∂w</div>
<div id="t11_8" class="t s1_8">in the network. To make the computaon of </div>
<div id="t12_8" class="t s2_8">∂L</div>
<div id="t13_8" class="t s2_8">∂w</div>
<div id="t14_8" class="t s1_8">clearer, an intermediate value </div>
<div id="t15_8" class="t s2_8">δ</div>
<div id="t16_8" class="t s5_8">=</div>
<div id="t17_8" class="t s2_8">∂L</div>
<div id="t18_8" class="t s2_8">∂w</div>
<div id="t19_8" class="t s1_8">, which </div>
<div id="t1a_8" class="t s1_8">is the paral derivave of the loss L with respect to the layer's output z. Then, the paral derivaves of the loss</div>
<div id="t1b_8" class="t s1_8">L with respect to each parameter assemble </div>
<div id="t1c_8" class="t s2_8">∂L</div>
<div id="t1d_8" class="t s2_8">∂w</div>
<div id="t1e_8" class="t s1_8">, are computed based on the intermediate value δ. </div>
<div id="t1f_8" class="t s1_8">The layers are indexed as l= 1, 2, . . .L, where L is the index of the output layer, each layer has an output</div>
<div id="t1g_8" class="t s2_8">z</div>
<div id="t1h_8" class="t s4_8">l</div>
<div id="t1i_8" class="t s1_8">, an intermediate value </div>
<div id="t1j_8" class="t s2_8">∂</div>
<div id="t1k_8" class="t s4_8">i</div>
<div id="t1l_8" class="t s5_8">=</div>
<div id="t1m_8" class="t s2_8">∂L</div>
<div id="t1n_8" class="t s2_8">∂z</div>
<div id="t1o_8" class="t s4_8">l</div>
<div id="t1p_8" class="t s1_8">, and an acvaon output </div>
<div id="t1q_8" class="t s2_8">a</div>
<div id="t1r_8" class="t s4_8">l</div>
<div id="t1s_8" class="t s5_8">=</div>
<div id="t1t_8" class="t s2_8">f</div>
<div id="t1u_8" class="t v2_8 s6_8">(</div>
<div id="t1v_8" class="t s2_8">z</div>
<div id="t1w_8" class="t s4_8">l</div>
<div id="t1x_8" class="t v2_8 s6_8">)</div>
<div id="t1y_8" class="t s1_8">(where f is the acvaon funcon). For </div>
<div id="t1z_8" class="t s1_8">example if sigmoid is used as the acvaon funcon, following formulize the method. </div>
<div id="t20_8" class="t v3_8 s2_8">z</div>
<div id="t21_8" class="t v3_8 s4_8">l</div>
<div id="t22_8" class="t v3_8 s5_8">=</div>
<div id="t23_8" class="t v3_8 s2_8">W</div>
<div id="t24_8" class="t v3_8 s4_8">l</div>
<div id="t25_8" class="t v3_8 s2_8">a</div>
<div id="t26_8" class="t v3_8 s4_8">l</div>
<div id="t27_8" class="t v3_8 s7_8">−</div>
<div id="t28_8" class="t v3_8 s8_8">1</div>
<div id="t29_8" class="t s1_8">where </div>
<div id="t2a_8" class="t v4_8 s2_8">w</div>
<div id="t2b_8" class="t v4_8 s8_8">0</div>
<div id="t2c_8" class="t v4_8 s4_8">l</div>
<div id="t2d_8" class="t v4_8 s2_8">is b</div>
<div id="t2e_8" class="t v4_8 s4_8">l</div>
<div id="t2f_8" class="t s1_8">which is bias</div>
<div id="t2g_8" class="t s2_8">a</div>
<div id="t2h_8" class="t s4_8">l</div>
<div id="t2i_8" class="t s5_8">=</div>
<div id="t2j_8" class="t s2_8">f</div>
<div id="t2k_8" class="t v5_8 s6_8">(</div>
<div id="t2l_8" class="t s2_8">z</div>
<div id="t2m_8" class="t s4_8">l</div>
<div id="t2n_8" class="t v5_8 s6_8">)</div>
<div id="t2o_8" class="t s5_8">=</div>
<div id="t2p_8" class="t s9_8">1</div>
<div id="t2q_8" class="t s9_8">1</div>
<div id="t2r_8" class="t s5_8">+</div>
<div id="t2s_8" class="t s2_8">e</div>
<div id="t2t_8" class="t s7_8">−</div>
<div id="t2u_8" class="t s4_8">z</div>
<div id="t2v_8" class="t sa_8">l</div>
<div id="t2w_8" class="t s2_8">L</div>
<div id="t2x_8" class="t s5_8">=</div>
<div id="t2y_8" class="t s9_8">1</div>
<div id="t2z_8" class="t s9_8">2</div>
<div id="t30_8" class="t s2_8">‖y</div>
<div id="t31_8" class="t s5_8">−</div>
<div id="t32_8" class="t s2_8">a</div>
<div id="t33_8" class="t s4_8">L</div>
<div id="t34_8" class="t s2_8">‖</div>
<div id="t35_8" class="t s8_8">2</div>
<div id="t36_8" class="t s1_8">,</div>
<div id="t37_8" class="t s1_8">By applying the gradient descent method to minimize the loss funcon, it can be shown that the weight</div>
<div id="t38_8" class="t s1_8">update of each layer is governed by the following equaon, which can be programmed iteravely.</div>
<div id="t39_8" class="t s2_8">w</div>
<div id="t3a_8" class="t s4_8">l</div>
<div id="t3b_8" class="t s5_8">=</div>
<div id="t3c_8" class="t s2_8">w</div>
<div id="t3d_8" class="t s4_8">l</div>
<div id="t3e_8" class="t s5_8">−</div>
<div id="t3f_8" class="t s3_8">∝</div>
<div id="t3g_8" class="t s2_8">∂L</div>
<div id="t3h_8" class="t s2_8">∂w</div>
<div id="t3i_8" class="t s4_8">l</div>

<!-- End text definitions -->


</div>
</body>
</html>
